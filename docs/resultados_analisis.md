# Resultados & An√°lisis

## 1. Calibraci√≥n de la c√°mara
En la Figuras 1 y 2 se muestran varias im√°genes del patr√≥n de calibraci√≥n (tablero de ajedrez) con las esquinas correctamente detectadas y dibujadas usando cv2.findChessboardCorners y cv2.drawChessboardCorners. Esto confirma que el patr√≥n fue reconocido de forma consistente en m√∫ltiples poses.

![Patrones reconocidos correctamente](assets/punto1_1a.png)
![Patrones reconocidos correctamente](assets/punto1_1b.png)

A partir de estos puntos 2D‚Äì3D se estimaron los par√°metros intr√≠nsecos de la c√°mara. La matriz K obtenida fue:

$$\begin{bmatrix}
3081.44 & 0 & 1984.29\\
0 & 3098.68 & 1524.75\\
0 & 0 & 1
\end{bmatrix}$$

Los valores focales $f_x=3081.44$ y $f_y=3098.68$ son muy similares (diferencia $‚âà 0.5$ %), lo que indica que los p√≠xeles del sensor son casi cuadrados y no hay deformaci√≥n marcada en un eje espec√≠fico.

El punto principal $(cx, cy)=(1984.3,¬†1524.8)$ est√° cerca del centro geom√©trico de la imagen $(2016.0,¬†1512.0)$; la distancia entre ambos es de $~34.2$ px, equivalente a $1.57$ % en $x$ y $‚Äì0.84$ % en $y$. Esto sugiere que el eje √≥ptico est√° bien alineado con el sensor y que no hubo desplazamientos severos de la lente.

Los coeficientes de distorsi√≥n estimados fueron:
* $k_1=0.0513$
* $k_2=‚Äì0.5059$
* $p_1=0.0045$
* $p_2=-0.0028$
* $k_3=0.4909$

El signo de $k_2$ y la forma visual observada en los bordes indican una distorsi√≥n tipo coj√≠n (pincushion), donde las l√≠neas rectas tienden a curvarse hacia adentro en las esquinas (Figuras 3 y 4).

El error medio de reproyecci√≥n fue de $0.47$ p√≠xeles. Este valor es bajo y confirma que el ajuste geom√©trico entre el modelo de c√°mara y las observaciones reales es consistente. En la Figura 3 se comparan im√°genes originales y sus versiones corregidas con cv2.undistort, donde se aprecia que las l√≠neas cercanas al borde se enderezan despu√©s de la correcci√≥n.

![Im√°genes antes y despu√©s de la correcci√≥n de distorsi√≥n](assets/punto1_2a.png)
![Im√°genes antes y despu√©s de la correcci√≥n de distorsi√≥n](assets/punto1_2b.png)

## 2. Transformaciones de intensidad
Se tomaron dos fotograf√≠as de la misma fachada, una en condiciones de luz diurna (~6 a. m.) y otra nocturna (~7 p. m.). Sobre esas dos im√°genes se aplicaron tres operaciones punto a punto implementadas manualmente:

* Ajuste de brillo: suma constante a cada canal RGB para aclarar u oscurecer la imagen saturando a $[0,255]$.

* Ajuste de contraste: escalamiento alrededor de la media para intensificar diferencias locales.

* Correcci√≥n gamma: remapeo no lineal $(ùêº^‚Ä≤=ùêº^ùõæ)$ que aclara sombras $(Œ≥<1)$ o comprime altas luces $(Œ≥>1)$.

En la Figura 4 se observan cuatro paneles: imagen diurna original, imagen nocturna original, imagen diurna tras correcci√≥n gamma y la misma operaci√≥n sobre la imagen nocturna. Se evidencia que la correcci√≥n gamma mejora especialmente la imagen nocturna, recuperando detalle en regiones oscuras sin sobreexponer completamente las zonas iluminadas.

Adicionalmente, se realizaron combinaciones aritm√©ticas entre la imagen de d√≠a $(A)$ y la de noche $(B)$: $A+B$, $A‚àíB$, $A√óB$ y $A√∑B$ (Figura 5).

* La suma resalta zonas iluminadas en cualquiera de las dos tomas.

* La resta permite identificar √°reas donde cambi√≥ la iluminaci√≥n entre d√≠a y noche (por ejemplo, luces artificiales).

* La multiplicaci√≥n enfatiza solo las regiones que son simult√°neamente brillantes en ambas im√°genes.

* La divisi√≥n resalta regiones iluminadas en una toma pero no en la otra, √∫til para detectar focos de luz nocturna.

## 3. Transformaciones geom√©tricas y animaci√≥n
Se defini√≥ una rutina que carga una imagen base y aplica, en secuencia, varias transformaciones geom√©tricas afines: traslaciones (desplazamientos en x/y), rotaciones alrededor del centro de la imagen y cambios de escala (zoom in / zoom out). Despu√©s de cada transformaci√≥n parcial se guard√≥ el fotograma resultante.

Con esta lista de fotogramas se gener√≥ una animaci√≥n tipo GIF usando matplotlib.animation.FuncAnimation. El resultado (ver Figura 5) muestra la imagen ‚Äúmovi√©ndose‚Äù, rotando y cambiando de tama√±o cuadro a cuadro, lo que demuestra que las transformaciones sucesivas se aplicaron en el orden correcto y producen un movimiento continuo.

## 4. Limitaciones observadas
Se analizaron las dos im√°genes de fachada (d√≠a y noche) en t√©rminos de su distribuci√≥n de intensidades. Cada imagen se transform√≥ a espacio YUV y se aplic√≥ ecualizaci√≥n de histograma √∫nicamente sobre el canal Y (luminancia), usando cv2.equalizeHist. Luego se reconstruy√≥ la imagen en RGB.

En las Figuras 6 y 7 se presentan, para cada caso (d√≠a y noche):

1. Imagen original.

2. Imagen ecualizada.

3. Histograma original de intensidades.

4. Histograma ecualizado.

Resultados principales:

* En la imagen nocturna, el histograma original est√° concentrado en valores bajos (oscuros). Tras la ecualizaci√≥n, el histograma se distribuye de forma m√°s uniforme y aparecen detalles que antes estaban casi negros.

* En la imagen diurna ocurre lo contrario: hab√≠a saturaci√≥n en zonas muy brillantes. La ecualizaci√≥n reduce ese pico y mejora el contraste en regiones claras.

*Conclusi√≥n:* la ecualizaci√≥n mejora la legibilidad visual tanto en baja iluminaci√≥n (recuperando sombras) como en alta iluminaci√≥n (recuperando textura en zonas casi blancas).

## 5. Segmentaci√≥n y conteo por color
Se captur√≥ una escena con m√∫ltiples objetos de colores distintos (por ejemplo, superficies azules, verdes, grises, blancas). La imagen se convirti√≥ a espacio HSV y para cada color se definieron rangos $[H_{min}, S_{min}, V_{min}] ‚Äì [H_{max}, S_{max}, V_{max}]$. Con esos rangos se generaron m√°scaras binarias (cv2.inRange), que luego se limpiaron con operaciones morfol√≥gicas para reducir ruido.

Posteriormente se extrajeron contornos con cv2.findContours, se dibujaron sobre la imagen original y se calcul√≥:

* El n√∫mero total de objetos detectados por color.

* El √°rea aproximada de cada objeto, en p√≠xeles, usando cv2.contourArea.

En la Figura 7 se muestra, para un color espec√≠fico (por ejemplo, azul):

* Imagen original.

* M√°scara binaria limpia.

* Contornos sobrepuestos y etiquetados.